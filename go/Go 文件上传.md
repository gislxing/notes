# Go æ–‡ä»¶ä¸Šä¼ 
## Sending big file with minimal memory in Go Goå®¢æˆ·ç«¯ä½¿ç”¨å°å†…å­˜ä¸Šä¼ å¤§æ–‡ä»¶

![img](img/1_XDleIjprsIV4KkaRCQdeVQ.jpeg)

â€‹                                                                                      é¥¥é¥¿çš„åœ°é¼ 

Most common way of uploading file(s) by http is splitting them in multiple parts (multipart/form-data), this structure helps greatly as we can also attach fields along and send them all in one single request.

é€šè¿‡httpä¸Šä¼ æ–‡ä»¶çš„æœ€å¸¸è§æ–¹å¼æ˜¯å°†å®ƒä»¬åˆ†æˆå¤šä¸ªéƒ¨åˆ†ï¼ˆmultipart / form-dataï¼‰ï¼Œè¿™ç§ç»“æ„éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜å¯ä»¥åœ¨ä¸€ä¸ªè¯·æ±‚ä¸­é™„åŠ å­—æ®µå¹¶å°†å®ƒä»¬å…¨éƒ¨å‘é€å‡ºå»ã€‚

A typical multipart request (example from Mozilla):

å…¸å‹çš„å¤šéƒ¨åˆ†è¯·æ±‚ï¼ˆæ¥è‡ªMozillaçš„ç¤ºä¾‹ï¼‰ï¼š

```html
POST /foo HTTP/1.1
Content-Length: 68137
Content-Type: multipart/form-data; boundary=---------------------------974767299852498929531610575
-----------------------------974767299852498929531610575
Content-Disposition: form-data; name="description"
some text
-----------------------------974767299852498929531610575
Content-Disposition: form-data; name="myFile"; filename="foo.txt" 
Content-Type: text/plain
(content of the uploaded file foo.txt)
-----------------------------974767299852498929531610575--
```

We will start with this simple implementation, standard package `mime/multipart` got our back:

æˆ‘ä»¬å°†ä»è¿™ä¸ªç®€å•çš„å®ç°å¼€å§‹ï¼Œæ ‡å‡†åŒ…`mime/multipart`å¾—åˆ°äº†æˆ‘ä»¬çš„å›æŠ¥ï¼š

```
buf := new(bytes.Buffer)
writer := multipart.NewWriter(buf)
defer writer.Close()
part, err := writer.CreateFormFile("myFile", "foo.txt")
if err != nil {
    return err
}
file, err := os.Open(name)
if err != nil {
    return err
}
defer file.Close()
if _, err = io.Copy(part, file); err != nil {
    return err
}
http.Post(url, writer.FormDataContentType(), buf)
```

`multipart.Writer` will automatically enclose the parts (files, fields) in boundary markup before sending them â¤ï¸ We donâ€™t need to get our hands dirty.

`multipart.Writer` åœ¨å‘é€å®ƒä»¬ä¹‹å‰ä¼šè‡ªåŠ¨å°†éƒ¨ä»¶ï¼ˆæ–‡ä»¶ï¼Œå­—æ®µï¼‰å°è£…åœ¨è¾¹ç•Œæ ‡è®°ä¸­â¤ï¸æˆ‘ä»¬ä¸éœ€è¦å¼„è„æ‰‹ã€‚

------

Above works great until you do some benchmark and see the memory allocation **grows linearly with the file size**, so what went wrong? It turns out that `buf` is fully buffered the whole file content, `buf` sequentially reads a modest 32kB from the file but wonâ€™t stop until it reaches EOF, so to hold the file content `buf` needs to be at least at the file size, plus some additional boundary markup.

ä¸Šé¢çš„å·¥ä½œå¾ˆæ£’ï¼Œç›´åˆ°ä½ åšä¸€äº›åŸºå‡†æµ‹è¯•å¹¶çœ‹åˆ°å†…å­˜åˆ†é…**éšæ–‡ä»¶å¤§å°çº¿æ€§å¢é•¿**ï¼Œæ‰€ä»¥å‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼Ÿäº‹å®è¯æ˜ï¼Œ`buf`æ•´ä¸ªæ–‡ä»¶å†…å®¹æ˜¯å®Œå…¨ç¼“å†²çš„ï¼Œ`buf`ä»æ–‡ä»¶ä¸­é¡ºåºè¯»å–ä¸€ä¸ª32kBï¼Œä½†æ˜¯ç›´åˆ°è¾¾åˆ°EOFæ‰ä¼šåœæ­¢ï¼Œæ‰€ä»¥è¦ä¿æŒæ–‡ä»¶å†…å®¹`buf`è‡³å°‘éœ€è¦æ–‡ä»¶å¤§å°ï¼ŒåŠ ä¸Šä¸€äº›é¢å¤–çš„è¾¹ç•Œæ ‡è®°ã€‚

HTTP/1.1 has a method of transfer data in chunks unboundedly, without specifying `Content-Length`of request body, this is an important feature we can utilize.

HTTP / 1.1æœ‰ä¸€ç§æ— é™åˆ¶åœ°ä¼ è¾“æ•°æ®çš„æ–¹æ³•ï¼Œæ²¡æœ‰æŒ‡å®š`Content-Length`è¯·æ±‚ä½“ï¼Œè¿™æ˜¯æˆ‘ä»¬å¯ä»¥åˆ©ç”¨çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§ã€‚

So `buf` causes problem, but how can we synchronize file content to the request without it? `io.Pipe` is born for these tasks, as the name suggests, it pipes writer to reader:

å› æ­¤`buf`å¯¼è‡´é—®é¢˜ï¼Œä½†æ˜¯å¦‚ä½•åœ¨æ²¡æœ‰å®ƒçš„æƒ…å†µä¸‹å°†æ–‡ä»¶å†…å®¹ä¸è¯·æ±‚åŒæ­¥ï¼Ÿ`io.Pipe`ä¸ºè¿™äº›ä»»åŠ¡è€Œç”Ÿï¼Œæ­£å¦‚å…¶åç§°æ‰€ç¤ºï¼Œå®ƒå°†ä½œå®¶ä¸è¯»è€…è”ç³»èµ·æ¥ï¼š

```
r, w := io.Pipe()
m := multipart.NewWriter(w)
go func() {
    defer w.Close()
    defer m.Close()
    part, err := m.CreateFormFile("myFile", "foo.txt")
    if err != nil {
        return
    }
    file, err := os.Open(name)
    if err != nil {
        return
    }
    defer file.Close()
    if _, err = io.Copy(part, file); err != nil {
        return
    }
}()
http.Post(url, m.FormDataContentType(), r)
```

If you dump the request above, the header reads:

å¦‚æœè½¬å‚¨ä¸Šé¢çš„è¯·æ±‚ï¼Œæ ‡é¢˜ä¸ºï¼š

```
POST / HTTP/1.1
...
Transfer-Encoding: chunked
Accept-Encoding: gzip
Content-Type: multipart/form-data; boundary=....
User-Agent: Go-http-client/1.1
```

Yep, `net/http` has handled the `Transfer-Encoding` and remove `Content-Length` without us manually doing anything. Wanna see the difference in memory allocation?

æ˜¯çš„ï¼Œ`net/http`å·²å¤„ç†`Transfer-Encoding`å’Œåˆ é™¤`Content-Length`æ²¡æœ‰æˆ‘ä»¬æ‰‹åŠ¨åšä»»ä½•äº‹æƒ…ã€‚æƒ³çœ‹çœ‹å†…å­˜åˆ†é…çš„å·®å¼‚å—ï¼Ÿ

```
Benchmark sending 16MB file
33471060 B/op
84767 B/op
```

Guess which one is the second approach? ğŸ˜‰

## Donâ€™t parse everything from client multipart POST  æœåŠ¡å™¨ç«¯å¤„ç†æ–‡ä»¶ä¸Šä¼ 

![img](img/1_4Iz1QACB-ebYVS0ALK4zFQ.jpeg)

â€‹                                                                                     Iâ€™m not a hoarder

Q: Whatâ€™s **wrong** with the code below (this is very typical way of parsing a multipart request):

è¯·é—®ï¼šä¸‹é¢çš„ä»£ç æœ‰ä»€ä¹ˆ**é—®é¢˜**ï¼ˆè¿™æ˜¯è§£æå¤šéƒ¨åˆ†è¯·æ±‚çš„éå¸¸å…¸å‹çš„æ–¹å¼ï¼‰ï¼š

```go
// in the body of a http.HandlerFunc
err := r.ParseMultipartForm(32 << 20) // 32Mb
if err != nil {
    http.Error(w, err.Error(), http.StatusBadRequest)
}
```

A: Nothing wrong with the code above, itâ€™s a hidden gotcha which is very easy to be oversight though.

ç­”ï¼šä¸Šé¢çš„ä»£ç æ²¡æœ‰é”™ï¼Œå®ƒæ˜¯ä¸€ä¸ªéšè—çš„é™·é˜±ï¼Œè™½ç„¶å¾ˆå®¹æ˜“è¢«å¿½è§†ã€‚

`ParseMultipartForm` will parse every single of part of request, if you send 100 files in a â€œchunkedâ€ encoding POST to the above endpoint, it will parse them all. Notice that 32Mb is the bytes allocated to the request body to store in memory, not the limit of request body, when full (says 33Mb), it will write to temporary directory.

`ParseMultipartForm`å°†è§£æè¯·æ±‚çš„æ¯ä¸€éƒ¨åˆ†ï¼Œå¦‚æœæ‚¨å°†â€œchunkedâ€ç¼–ç POSTä¸­çš„100ä¸ªæ–‡ä»¶å‘é€åˆ°ä¸Šè¿°ç«¯ç‚¹ï¼Œå®ƒå°†å…¨éƒ¨è§£æå®ƒä»¬ã€‚è¯·æ³¨æ„ï¼Œ32Mbæ˜¯åˆ†é…ç»™è¯·æ±‚ä½“çš„å­—èŠ‚å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè€Œä¸æ˜¯è¯·æ±‚ä½“çš„é™åˆ¶ï¼Œå½“æ»¡ï¼ˆ33Mbï¼‰æ—¶ï¼Œå®ƒå°†å†™å…¥ä¸´æ—¶ç›®å½•ã€‚

------

A simple triage ä¸€ä¸ªç®€å•çš„åˆ†ç±» :

```go
// add this line on top
r.Body = http.MaxBytesReader(w, r.Body, 32<<20+512)
...
```

Above will limit the POST body size to 32.5Mb and throw error if client attempt to send more than that. At least, we donâ€™t have to worry if client maliciously draining server resource.

å¦‚æœå®¢æˆ·ç«¯å°è¯•å‘é€è¶…è¿‡è¯¥å€¼ï¼Œåˆ™ä¸Šé¢å°†POSTä¸»ä½“å¤§å°é™åˆ¶ä¸º32.5Mbå¹¶æŠ›å‡ºé”™è¯¯ã€‚è‡³å°‘ï¼Œå¦‚æœå®¢æˆ·ç«¯æ¶æ„è€—å°½æœåŠ¡å™¨èµ„æºï¼Œæˆ‘ä»¬ä¸å¿…æ‹…å¿ƒã€‚

But what if we want the full control of data coming in? E.g.: file size limit or file type on specific field. With the standard `ParseMultipartForm`, we probably canâ€™t achieve that.

ä½†æ˜¯å¦‚æœæˆ‘ä»¬æƒ³è¦å®Œå…¨æ§åˆ¶æ•°æ®å‘¢ï¼Ÿä¾‹å¦‚ï¼šç‰¹å®šå­—æ®µçš„æ–‡ä»¶å¤§å°é™åˆ¶æˆ–æ–‡ä»¶ç±»å‹ã€‚æœ‰äº†æ ‡å‡†`ParseMultipartForm`ï¼Œæˆ‘ä»¬å¯èƒ½æ— æ³•åšåˆ°è¿™ä¸€ç‚¹ã€‚

These are the things I want to have in my handler:

è¿™äº›æ˜¯æˆ‘æƒ³åœ¨æˆ‘çš„å¤„ç†ç¨‹åºä¸­æ‹¥æœ‰çš„ä¸œè¥¿ï¼š

- file type validation 

  æ–‡ä»¶ç±»å‹éªŒè¯

- file size validation 

  æ–‡ä»¶å¤§å°éªŒè¯

- whitelist â€œfieldâ€ names (so we donâ€™t write down any file we donâ€™t want to)

  ç™½åå•â€œå­—æ®µâ€åç§°ï¼ˆæ‰€ä»¥æˆ‘ä»¬ä¸å†™ä¸‹ä»»ä½•æˆ‘ä»¬ä¸æƒ³è¦çš„æ–‡ä»¶ï¼‰

- parse fields in order and terminate if not (this is opinionated, but who wouldnâ€™t prefer bounded and deterministic)

  æŒ‰é¡ºåºè§£æå­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™ç»ˆæ­¢ï¼ˆè¿™æ˜¯è‡ªä»¥ä¸ºæ˜¯ï¼Œä½†è°ä¸å–œæ¬¢æœ‰ç•Œå’Œç¡®å®šæ€§ï¼‰

- terminate early if any validation fails

  å¦‚æœä»»ä½•éªŒè¯å¤±è´¥ï¼Œåˆ™æå‰ç»ˆæ­¢

- buffering all the way, no pre-allocation

  ä¸€è·¯ç¼“å†²ï¼Œæ²¡æœ‰é¢„å…ˆåˆ†é…

So this is what I come up with, for demonstration purpose, POST will have 2 fields named: `text_field` and `file_field`, bear with me for below extremely verbose code:

æ‰€ä»¥è¿™å°±æ˜¯æˆ‘æƒ³å‡ºæ¥çš„ï¼Œå‡ºäºæ¼”ç¤ºç›®çš„ï¼ŒPOSTå°†æœ‰ä¸¤ä¸ªåä¸ºçš„å­—æ®µï¼š`text_field`å¹¶ä¸”`file_field`ï¼Œè¯·è€å¿ƒç­‰å¾…ä»¥ä¸‹éå¸¸è¯¦ç»†çš„ä»£ç ï¼š

```go
// function body of a http.HandlerFunc
r.Body = http.MaxBytesReader(w, r.Body, 32<<20+1024)
reader, err := r.MultipartReader()
if err != nil {
    http.Error(w, err.Error(), http.StatusBadRequest)
    return
}
// parse text field
text := make([]byte, 512)
p, err := reader.NextPart()
// one more field to parse, EOF is considered as failure here
if err != nil {
    http.Error(w, err.Error(), http.StatusInternalServerError)
    return
}
if p.FormName() != "text_field" {
    http.Error(w, "text_field is expected", http.StatusBadRequest)
    return
}
_, err = p.Read(text)
if err != nil && err != io.EOF {
    http.Error(w, err.Error(), http.StatusInternalServerError)
    return
}
// parse file field
p, err = reader.NextPart()
if err != nil && err != io.EOF {
    http.Error(w, err.Error(), http.StatusInternalServerError)
    return
}
if p.FormName() != "file_field" {
    http.Error(w, "file_field is expected", http.StatusBadRequest)
    return
}
buf := bufio.NewReader(p)
sniff, _ := buf.Peek(512)
contentType := http.DetectContentType(sniff)
if contentType != "application/zip" {
    http.Error(w, "file type not allowed", http.StatusBadRequest)
    return
}
f, err := ioutil.TempFile("", "")
if err != nil {
    http.Error(w, err.Error(), http.StatusInternalServerError)
    return
}
defer f.Close()
var maxSize int64 = 32 << 20
lmt := io.LimitReader(p, maxSize+1)
written, err := io.Copy(f, lmt)
if err != nil && err != io.EOF {
    http.Error(w, err.Error(), http.StatusInternalServerError)
    return
}
if written > maxSize {
    os.Remove(f.Name())
    http.Error(w, "file size over limit", http.StatusBadRequest)
    return
}
// schedule for other stuffs (s3, scanning, etc.)
```

Some key points for the code above:

ä¸Šé¢ä»£ç çš„ä¸€äº›å…³é”®ç‚¹ï¼š

- Only fetch first 2 parts in POST body, handler will expect `text_field` then `file_field`

  åªåœ¨POSTä¸»ä½“ä¸­è·å–å‰2ä¸ªéƒ¨åˆ†ï¼Œ`text_field`ç„¶åå¤„ç†ç¨‹åºä¼šæœŸæœ›`file_field`

- Assert file type using `bufio.Reader` wrapping Part reader (peeking first 512 bytes)

  ä½¿ç”¨`bufio.Reader`åŒ…è£…éƒ¨ä»¶è¯»å–å™¨ï¼ˆå…ˆæŸ¥çœ‹512å­—èŠ‚ï¼‰æ–­è¨€æ–‡ä»¶ç±»å‹

- Limit file size with `io.LimitReader` (with 1 byte offset to see if part reader still has some data left)

  é™åˆ¶æ–‡ä»¶å¤§å°`io.LimitReader`ï¼ˆä½¿ç”¨1ä¸ªå­—èŠ‚çš„åç§»é‡æ¥æŸ¥çœ‹éƒ¨åˆ†é˜…è¯»å™¨æ˜¯å¦è¿˜æœ‰ä¸€äº›æ•°æ®ï¼‰

The code can be definitely refactored to treat file and text fields in general but you got the idea, let me know what you think in the comment section.

ä¸€èˆ¬æ¥è¯´ä»£ç å¯ä»¥è¢«é‡æ„æ¥å¤„ç†æ–‡ä»¶å’Œæ–‡æœ¬å­—æ®µï¼Œä½†ä½ æ˜ç™½äº†ï¼Œè®©æˆ‘çŸ¥é“ä½ åœ¨è¯„è®ºéƒ¨åˆ†çš„æƒ³æ³•

Happy coding gophers!